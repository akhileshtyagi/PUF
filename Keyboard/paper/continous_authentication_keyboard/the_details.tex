% here the evidence that the claims are correct is presented
% the structure, about 3 paragraphs for each analysis
% 1 This is my analysis
% 2 This analysis shows/demonstrates x
% 3 x supports my claim in the following way
\section{The Details}
\label{the_details}

% begin by describing what our implementation is
% answer the question, "what did you do"
In order to answer the question of
whether or not touch screen interactions may be used
in order to distinguish between users
a system is implemented to gather and analyze data
from interactions with the touchscreen of an Android device.
This data consists of location, pressure, and time
values associated with user's interactions with a soft keyboard.
%
For gathering purposes,
a keyboard application was modified to record
the necessary data values.
%
%TODO say how man users where enlisted
Several users were enlisted to acquire
a large amount of touch screen data on Nexus $7$ tablets.
%
In order to analyze the collected data,
the system described in \ref{the_solution}
has been constructed.

% discuss false_positive and false_negative percentages
% what are these metrics (definitions)
% what did we find them to be (values)
In order to measure the performance of the system
it is useful to define some metrics
which give insight into the user experience.
%
We use false positive percentage,
the ratio of identities which are incorrectly classified as the user
to the total number of identities authenticated,
and
false negative percentage,
the ratio of identities which are incorrectly classified as not the user,
to the total number of identities authenticated.
%
These metrics can be used to describe how the device will
behave from the user's perspective.
%
False positives allow illegitimate users access to the device
which may result in loss of data should the device be compromised.
%
On the other hand,
false negatives deny device access to the legitimate user.
A large number of false negatives would conceivably 
be very frustrating to the user.
%
There is a natural inverse relationship between
false positive percentage and false negative percentage.
The authentication can be made less restrictive to 
engender fewer false negatives, but
in exchange a greater proportion of
illegitimate users will also authenticate.
%
This relationship is exhibited in Figure \ref{fig:threshold_vs_percentages}
where one of our system's parameters, authentication threshold, 
is adjusted to allow varying rates 
of false positive percentage and false negative percentage.

% picture of false positives and false negatives in our system
\ExecuteMetaData[graphics.tex]{threshold}

% discuss authentication_accuracy
% what is is this metric
% how is it measure
% why is it a good way to measure how well the system preforms
Another metric used to describe the performance of our system
is authentication accuracy.
%
Defined as the 
number of correct authentications by
the total number of authentications,
the goal of this metric is to
aggregate
false positive percentage and
false negative percentage 
to say something about how well our system can distinguish between
legitimate and illegitimate user identities.
%
Authentication accuracy is 
expressed as a percentage
related to 
false positive percentage and
false negative percentage by
$authentication\_accuracy = 1.0 - (false\_positive\_percent) - (false\_negative\_percent)$.
%
This is intuitive as both 
false positive percentage and
false negative percentage 
represent incorrect authentication results.

% give intuition about how long it might take the user
% to generate enough touch screen interactions to attain
% a given accuracy ( it would take x minutes of device use to attain x% accuracy )
%
% how long does it to generate x touches?
%%%
In our system, we record touch pressures generated by 
users through the soft keyboard of an Android device. 
Once we have collected a sufficient number of touch screen interactions, 
which is the training phase, we build 
a user profile or model
as a representation of the user identity.
%
% describe what this user identity is authenticated against
New touch screen interactions can then be compared
against this identity to determine if
these new interactions have come from the same user
that formed the identity.
%
The collection process can be transparent to the user,
happening in the background under normal use conditions.
%
Figure \ref{fig:authentication_accuracy} 
shows the relationship between
the total number of touch screen interactions used in authentication
and the achievable authentication accuracy.
%
Touch screen interactions in authentication
are used to both
construct the user identity from a number of older interactions and
construct an identity to compare against the user identity 
from the more resent interactions.

% describe the performance of the system in terms of
% 1. aggregate performance
% 2. distinguishing user sets:
% 2.1. different user, different device
% 2.2. different user, same device
% 2.3. same user, different device
% 2.4. same user, same device
%
%1. aggregate performance
%
% describe what the goal of our system is
% frame authentication accuracy as a representation of
% how well the goal is accomplished with any given number of 
% touch screen interactions
The goal is to determine the probability that
the more resent interactions
were generated by the same user-device which
generated the older interactions.
%
The accuracy of this probability
being correctly above an authentication threshold 
is what is being displayed in 
Figure 
%\ref{fig:authentication_accuracy}
\ref{fig:total_touches_vs_authentication_accuracy}
.
%
Of course
the information presented in the chart 
only supports the
the suggestion that the system is practical 
if the time to generate touch screen interactions is known.
%
In order to get an intuitive feel for this,
we reference studies which have tested
the number of words a user generates per minute
while using a soft keyboard.
%
\cite{mackenzie1999text} reported that a
novice user can enter information through 
a soft keyboard at a rate of $20.2$ words per minute with
expert rates averaging $43$ words per minute.
%
A word consists of on average five letters, 
a rate of $101$ touch interactions per minute for the novice user.
%
This means in the average use case, 
a user can generate $1000$ touch interactions in $5-10$ minutes of 
soft keyboard use.
%
% describe how authentication accuracy increases given touch interactions
%TODO redo these numbers
Given this,
the graph may be interpreted in the following way,
an authentication accuracy of $70\%$ is achievable 
when the user has generated $5000$ touch interactions
taking $25-50$ minutes of use.
%
After an additional $5000$ touches have been generated,
an authentication accuracy above $80\%$ is achievable.
Increasing the number of interactions 
by an additional $5000$ to $15000$ yields
an authentication accuracy of $90\%$.
%
This training can occur in a non-intrusive way
assuming the touch data is being collected over time in the background.
%%%

% total touch screen interactions vs authentication accuracy
\ExecuteMetaData[graphics.tex]{total}

%TODO describe the performance of the system in terms of
% 2.1. different user, different device
%TODO

% 2.2. different user, same device
%TODO

% 2.3. same user, different device

%TODO

% 2.4. same user, same device
%TODO

% discussion of the model parameters in general
% say what each of them were and their impact on the system
% window, token, time_threshold, (user_model_size, auth_model_size), authentication_threshold
Achieving the above accuracies required
tuning of the system.
%
There are a number of parameters used to 
modify the functionality of the system.
%
We preformed tests to optimize these parameters
such that they produce the highest authentication accuracy.
%
% list of parameters
These parameters are
window,
token,
time threshold,
user model size,
auth model size, and
authentication threshold.
%
% talk about how all these parameters fit together
These parameters interact with the Markov model 
where integer window describes the size of the $n-grams$,
integer $k$ token defines the number of tokens per location.
In other words, each location or key has $k$ pressure
ranges which are considered different.
%
Time threshold defines the maximal amount of time
allowed for consecutive touch interactions 
to be considered part of the same $n-gram$.
The intuition for time threshold is that
touch screen interactions which are sufficiently far 
apart in time are not likely to be related.
%
% talk about how user model size and auth model size are used
User model size and auth model size influence
the the authentication.
%
Section \ref{the_solution} describes
the authentication system in which two models are compared.
One model built from the most resent touch interactions
the other from older interactions.
These models are then compared to develop
a probability of them having come from the same user-device pair.
%
User model size describes the the number of touch interactions used
to construct the model of other interactions while
auth model size describes the number of touch interactions
used in the newer model.

% this is more of a WHY section NOT a WHAT section
% now go into detail on each of the model parameters affected the system
% present data with regards to each of the parameters
% 1 This is my analysis
% 2 This analysis shows/demonstrates x
% 3 x supports my claim in the following way
% 4 talk about the findings from each parameter
%
% window 
Window size $= n$ defines the size of the $n-grams$
used in the Markov model.
%
% give example
For example,
$n = 3$ means $3-grams$ are used leading to a Markov model where
sets of $3$ states predict the next state with some probability.
%
% describe findings in picture
Figure \ref{fig:window_size_vs_authentication_accuracy}
describes how window size affects the authentication accuracy
with all other parameters held constant.
%TODO

% window size vs authentication accuracy
\ExecuteMetaData[graphics.tex]{window}

% token
Token $= k$ defines the number of pressure ranges
into which each location is divided.
%
% give example
For instance,
if $k = 3$ 
then touching the screen area enclosed by
the $j$ key will be represented by one of three states
in the Markov model depending on the
pressure range in which the touch screen interaction falls.
% 
% describe findings in picture
%TODO

% time_threshold
% what is it
Time threshold defines the maximal amount of time
allowed for consecutive touch interactions 
to be considered part of the same $n-gram$.
% 
% give example
For example,
suppose we have a model where $n = 2$ and
states $X$, $Y$, $Z$ occur.
There is $100ms$ between $X$ and $Y$, and
$200ms$ between $Y$ and $Z$.
If the time threshold is set to
$\geq 200 ms$, 
then $[X,Y]$ and $[Y,Z]$ will be included as an $n-gram$ in the model.
If however time threshold is set to $< 200 ms$
then only $[X,Y]$ will be included as an $n-gram$ in the model.
%
% describe findings in picture
%TODO

% user_model_size and auth_model size
The user model is a model constructed from 
touch interactions thought to have originated from
the legitimate user.
The number of interactions used in the construction of this model
is termed user model size.
Similarly,
the number of interactions used in the construction of
the model to be compared against the user model
is know as the auth model size.
%
% be sure to describe authentication accuracy here
% and how it is related to user_model_size and auth_model_size
% describe findings in picture
Figure \ref{fig:authentication_accuracy}
describes how authentication accuracy depends on 
user model size, auth model size, and 
the total number of touch interactions in both models.
%
The message of this chart is that
the total number of touch interactions used in the authentication
has a stronger relationship to
authentication accuracy compared to
user model size or auth model size alone.

% authentication accuracy vs touch screen interactions
% this shows user model size, auth model size, and total size against
% authentication accuracy
\ExecuteMetaData[graphics.tex]{authentication}

% authentication threshold
% what is it
The distance computation between the 
user model and the auth model
results in a $0.0 \leq d \leq 1.0$ where
$d$ represents the distance between the models.
%
$(1 - d)$ is taken to be the authentication value.
The authentication value is compared against the
authentication threshold to determine if the authentication is passed.
% 
% give example
In other words the authentication passes if
$(1 - d) \geq$ authentication threshold.
%
% why is the authentication threshold significant?
The authentication threshold is significant
because in theory it could be used to adjust the 
performance of the system at run time.
%
For example,
If the system is experiencing many false negatives
then the authentication might be adjusted downward.
This will make the system less restrictive,
allowing for higher levels of difference between models to pass authentication.
%
While a lower authentication threshold will allow for more authentic users
to pass authentication, it will also allow more illegitimate users to pass.
%
A test for false negatives might be carried out in the following way.
Suppose that every time the system has an event where $(1 - d) <$ authentication threshold,
the user is locked out and must re-authenticate with some other method.
Perhaps every time the user authenticates with this other method after
such an event the system could record a false negative.
%
There cannot be a test for false positives.
The existence of such a test presupposes 
knowledge about the user which cannot be known.
Namely for such a test to exist,
it will be necessary to know whether or not
the user is legitimate.
Having this knowledge will render the system useless
as the purpose of the system is the determine whether a user is authentic or not.
%
Since there cannot be a test for false positives,
it will make sense to begin with a high threshold which
could be adjusted down over time as false negatives occur.
%
Eventually the system will reach an equilibrium where
false negatives do not occur and 
false positives are minimized.

% discuss iterations of the difference computation
% say what worked and what didn't work
% discuss what we were seeing that motivated specific design choices
%
% weighted windows and tokens in difference computation
% why did we do this?
The windows and tokens in the \dots 
are weighted by \dots
to help \dots
%TODO

% define confidence interval in general
% ( psuedo algorithmic description might be good here )
We found significant difference, approximately $10\%$, 
variation in the achievable accuracies for some data sets.
This drove the development of a data set metric to
understand how well the data might characterize a user.
%
Too much variability in the data set might make\dots
% what is the problem with too much variability
%TODO
%
% describe the computation
\begin{enumerate}
\item \dots
\end{enumerate}

% define confidence interval for the difference computation
A similar computation can be used to develop 
a confidence interval for the difference between two data sets.
%
We want to describe the variance in the distance 
between the data sets.
The intuition is that a high variance in the distance
may result in inaccurate distance computations therefore
less confidence should be put in the authentication result 
computed by our system.
%
% describe how the confidence interval is computed for the distance 
% ( psuedo algorithmic description might be good here )
\begin{enumerate}
\item \dots
\end{enumerate}
%TODO

% talk about how this correlates with the Jensen Shannon divergence between the sets
% ( perhaps not if I find there is no correlation )
%TODO

% talk about distance vector confidence
% how does this relate to the accuracy of authentication
%TODO

% discuss computation time on the nexus 7
% How does changing different model parameters affect run time
%
% user_model_size and auth_model_size
Figure \ref{fig:nexus_total_size_time} describes the
computation time necessary to preform the authentication on a Nexus $7$ tablet.
This time is given as a function of
the total number of touch screen interactions used to build
both the user model and the authentication model.
%
The message communicated by this figure is 
that there is an increase in computation time 
with the total number of touch screen interactions used.
%
This can be compared with 
Figure \ref{fig:total_touches_vs_authentication_accuracy}
to show the relationship between 
computation time and achievable accuracy.
%
For instance,
at $5000$ touch screen interactions an authentication accuracy of $70\%$
can be achieved with $1$ second of computation time.
At $10000$ touch screen interactions an authentication accuracy of $80\%$
can be achieved with $3$ second of computation time.
At $15000$ touch screen interactions an authentication accuracy of $90\%$
can be achieved with $4$ second of computation time.

%TODO was there no significant difference on computation time
%TODO for changing the other parameters? ( measure and comment on them )
%TODO

% total touchscreen interactions vs computation time on nexus 7
\ExecuteMetaData[graphics.tex]{nexus}

% describe the data collection process
%%%
Touchscreen data for touch pressure models in this experiment 
was generated using a keyboard application created for the Android. 
This keyboard extracts and records all necessary information 
from {\tt MotionEvent} objects generated by Android in response to
users' interactions with the keyboard.
This application was installed on Nexus $7$ tablets.
Users were then asked to play a typing game 
in order to help expedite the data collection process.
%TODO modify the atleast
After the users had generated at least five thousand touches the data was collected from the user's device to train the profile.
%
%TODO modify the number of users for the number who actually collect data
The results presented here are derived from the touch data generated by two users.
These users each used two different devices creating four user-device pairs
each having a large number of touch interactions.
%%%

% describe how the data looked 
% (normal distribution?)
% (q,q plot?)
% what did this cause us to decide to do?
% %TODO (potentially cpy-pste discussion from conference version)
%%%
% describe the distribution of the data
% describe how the data is related to a normal distribution
In building the model we remove some touches likely to be mistakes by the user or simply outliers in the data set.
%
%TODO this sentence doesn't fit, it doesn't describe what we do with this information
The distribution of touch pressure values is 
calculated for each square button area on the touchscreen. 
In our system these areas correspond to keys of the soft keyboard.
%
In order to develop PUF reproducibility,
the distribution of touchscreen pressure needs to be examined.
%
Figure \ref{fig:normal_distribution} plots the density of 
touch pressures from one of the test users.
%
The Shapiro-Wilk normality test \cite{shapiro1965analysis} was conducted
using $5000$ pressure points depicted in
Figure \ref{fig:normal_distribution}.
%
The results, {\tt W = 0.97244, p-value < 2.2e-16}.
$W=0.97244$ describes how closely the data conforms to a normal distribution.
$W=1.0$ would suggest the data set is perfectly normal.
$p-value=2.2e^{-16}$ indicates a low probability that
$W$ can be explained by chance variation.
%
The null hypothesis of the Shapiro-Wilk is
data comes from a normally distributed set.
$p-value<0.05$ suggests the null hypothesis should be rejected.
It is highly likely that the sample is not normally distributed.
%
%TODO connect the previous idea to this one
% how does the fact that the data isn't entirely normal suggest
% we should look at the qq plot?
%TODO
%
The Q-Q Plot for this data, Figure \ref{fig:qq_plot},
suggests the distribution differs from normal
by a slight right skew.
%
The Shapiro-Wilk normality test,
Q-Q Plot, 
and density plot
all suggest the touchscreen pressure data is not normally distributed.

% pdf of touch screen pressure data
\ExecuteMetaData[graphics.tex]{normal}

% describe what we did with the data to remove outliers
%TODO mu +- 2 sigma doesn't exactly fit here
From the token sequence,
a normal distribution mean and variance ($\mu$ and $\sigma$) 
values are estimated for each soft keyboard location or key.
%
If a touch interaction's pressure value falls outside of
$\mu \pm 2\sigma$ for a given key, 
then the touch interaction is not included in any of the $n$-token sequences. 
Figure \ref{fig:token_creation} illustrates 
this tokenization process.
The pressure values falling within $\mu \pm 2\sigma$ are tokenized
into a predetermined number of tokens $k$. 
$k=7$ token ranges in Figure \ref{fig:token_creation}.
The value of $\mu \pm 2\sigma$ was chosen because statistically $95.45$\% of touches 
will fall withing this range for normally distributed data \cite{threesigmarule}.
%
Through the data is not normally distributed,
we can pick out values from which x.
$95.45$\% corresponds to $1.69$ theoretical quantiles in \ref{fig:qq_plot}.
%
The function of the Q-Q Plot is to 
compare two distributions.
By taking data $\mu \pm 2\sigma$,
equivalent to $0 \pm 1.69$ theoretical quantiles,
we capture user data which is
linearly related to a normal distribution.
In other words if the data in this range
were multiplied by some factor,
it would appear to have come from a normal distribution.
%%%
%TODO

% q-q plot of touch screen pressure data
\ExecuteMetaData[graphics.tex]{qq}

% in other words what did we do to produces the numbers presented above
% describe how the data was analyzed
The collected data is analyzed using a program
developed to explore the effect of changing
parameters
$n$ window size, $k$ token size, time threshold,
user model size, and auth model size on
authentication accuracy.
%
The goal of the program is to
explore the space and determine a
set of a parameters which maximize authentication accuracy.

% include mention of some problems which presented themselves
Some notable problems presented themselves
throughout the course of this work
which could influence the usability of such a 
system in a practical sense.
%
The Android \textbf{MotionEvent} class \textbf{getPressure()} method
used to collect pressure data in our system
does not always return a high granularity of values.
The pressure values are sometimes grouped
into large steps.
There might, for example,
be $8$ steps between $0.0$ and $1.0$ on some devices.
This is a problem for our system which uses
these pressure values to understand user variability.
%
The problem seems to be device dependent
suggesting that the device drivers may have a role to play
in decreasing the reported graininess of pressure.
Another possibility might be the values
reported by the sensors,
Perhaps these sensors only report a small number of steps.

% state the performance impact on our system
% say how fine grained the pressure data is on the nexus 7
On the Nexus $7$ tablets used to test this implementation,
the pressure data from the touchscreen is 
reported at a precision of $0.096$ by the {\tt getPressure()} method.
This measurement has been determined
by finding the minimum difference between
any two pressure values in one of our data sets.
%
There is a small probability the precision could
be greater if two adjacent pressure measurements
were never taken in the dataset.
%
The precision of {\tt getPressure()} is
known to vary among devices.
We have not encountered any inconsistency
in the precision among devices of the same type (eg. Nexus $7$).
%
Devices with less precise values returned from
{\tt getPressure()}
compared to those pressure values on the Nexus $7$
tended to preform worse.
%
This makes intuitive sense as the basis for the system
is that pressure may be used as a user and device biometric.

% tie all analysis's back to the claims
Where does this leave us?
The goal in preforming these tests was to show it is possible to construct
an 
%
unobtrusive system which 
establishes a user identity 
and a device identity
based on pressure values 
derived from user touch screen interactions.
%
Further to show that this identity may be 
distinguished from other 
user and device identities with accuracy ($70-90+\%$)
in ($1-5 sec$) on a Nexus $7$ tablet.
%
% discuss how all of these claims have been accounted for
All of these claims have been accounted for
in the above discussion.
%
% relate back to solving the problem of 
% insufficient authentication after the lock screen has been bypassed
Such a system provides a reasonable step forward in
securing mobile devices in cases where the lock screen has
been bypassed by an illegitimate user.